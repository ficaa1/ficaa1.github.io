[
  
  {
    "title": "Homelab Series Part 1: Building a Secure VPN Gateway with Docker",
    "url": "/posts/homelab-vpn-gateway/",
    "categories": "homelab, docker, networking",
    "tags": "",
    "date": "2025-07-15 13:28:21 +0200",
    





    
    "snippet": "Welcome to the first post in my new series on building a fully automated mediaecosystem in my homelab. Before we can get to the fun stuff like media serversand request systems, we need to build a s...",
    "content": "Welcome to the first post in my new series on building a fully automated mediaecosystem in my homelab. Before we can get to the fun stuff like media serversand request systems, we need to build a solid, secure foundation. For any servicesthat reach out to the internet, I want to ensure that traffic is routed through aVPN.The goal is to create a “VPN gateway” container. Any other containers that needsecure internet access can then simply use this container’s network stack,forcing all their traffic through the VPN tunnel without any complex routingrules on the host.The Architecture: A Dedicated WireGuard GatewayWhile there are many popular all-in-one VPN containers, I opted for a morespecific and performant solution for my provider (Private Internet Access):thrnz/docker-wireguard-pia.This container is purpose-built to maintain a stable WireGuard tunnel to PIA. Inmy experience, this approach has proven to be more reliable and has yieldedfaster connection speeds than other, more generalized solutions.You’ll notice in the docker-compose.yml below that I’ve named the servicegluetun. This is just a convenient, descriptive name for the service’s role asa VPN gateway, even though the underlying image is thrnz/docker-wireguard-pia.Here is the docker-compose.yml for my downloader stack:version: \"3\"services:  gluetun:    container_name: gluetun    # This image is specifically for WireGuard with PIA    image: thrnz/docker-wireguard-pia    cap_add:      - NET_ADMIN    networks:      - staticnet    volumes:      - pia:/pia    environment:      # Replace with your actual PIA credentials      - USER=YOUR_VPN_USERNAME      - PASS=YOUR_VPN_PASSWORD      - LOC=YOUR_VPN_LOCATION      # This allows local devices to still access the services      - LOCAL_NETWORK=192.168.1.0/24    sysctls:      - net.ipv4.conf.all.src_valid_mark=1    ports:      # Port forward all necessary ports for the services that will use this network      - 8080:8080 # qBittorrent WebUI      - 6881:6881 # qBittorrent P2P      - 6881:6881/udp # qBittorrent P2P      - 9117:9117 # Prowlarr WebUI    restart: always  qbittorrent:    image: lscr.io/linuxserver/qbittorrent:latest    container_name: qbittorrent    # This is the magic line!    network_mode: \"service:gluetun\"    environment:      - PUID=1000      - PGID=1000      - TZ=Etc/UTC      - WEBUI_PORT=8080    volumes:      - /opt/qbittorrent:/config      - data:/data      - nvme_volume:/nvme    restart: always  prowlarr:    container_name: prowlarr    image: ghcr.io/hotio/prowlarr    # Prowlarr also uses the gluetun network stack    network_mode: \"service:gluetun\"    environment:      - PUID=1000      - PGID=1000      - TZ=Etc/UTC    volumes:      - prowlarr:/config    restart: alwaysvolumes:  prowlarr:  pia:  nvme_volume:    external: true    name: nvme_volume  data:    external: true    name: datanetworks:  staticnet:    external: true    name: staticnetKey ConceptsThe most important line in this configuration is network_mode: \"service:gluetun\". This tells Docker that the qbittorrent and prowlarr containers should not get their own network interface. Instead, they share the network stack of the gluetun service.This has two major benefits:  Simplicity: I don’t need to configure anything inside qBittorrent or Prowlarr. They operate as if they’re on a normal network, but all their traffic is transparently routed through the gateway’s VPN tunnel.  Security: If the gluetun container fails or the VPN disconnects, the network stack for the dependent services goes down with it. This acts as a kill-switch, preventing any accidental IP leaks.What’s Next?With our secure foundation in place, we can now build the services that will use it. In the next post, I’ll cover the “arr” stack (Sonarr, Radarr, Overseerr) and how it integrates with our downloaders to create a fully automated media acquisition pipeline."
  },
  
  {
    "title": "Fish shell and tmux config files",
    "url": "/posts/Fish-shell-and-tmux-conf/",
    "categories": "",
    "tags": "",
    "date": "2024-11-04 00:00:00 +0100",
    





    
    "snippet": "Fish shell configif status is-interactive    # Commands to run in interactive sessions can go here    zoxide init --cmd cd fish | source    fzf_configure_bindings --directory=\\ct    eval \"$(/home/l...",
    "content": "Fish shell configif status is-interactive    # Commands to run in interactive sessions can go here    zoxide init --cmd cd fish | source    fzf_configure_bindings --directory=\\ct    eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"end# function fzf --wraps=fzf --description=\"Use fzf-tmux if in tmux session\"#   if set --query TMUX#     fzf-tmux $argv#   else#     command fzf $argv#   end# endabbr -a ga git addabbr -a xsel xsel -i -babbr -a gr git rebase -iabbr -a gpr git pull --rebaseabbr -a gp git push-forabbr -a cdp cd ~/git/projectabbr -a gs git status --columnabbr -a gca git commit -aabbr -a gc git commitabbr -a gl git log --onelineabbr -a b batcatabbr -a gco git checkoutabbr -a g gitabbr -a bc batcat --style=\"header,rule\"abbr -a ansp ansible-playbook -i ansible/inventory.yml ansible/plays/pdt_push_config.yml --tags=productabbr -a ansr ansible-playbook -i ansible/inventory.yml ansible/plays/pdt_restart.ymlabbr -a e eza -la --icons -snewabbr -a et eza -la --icons -T -snewabbr -a k kubectlbind \\e\\cx cdiset fzf_diff_highlighter delta --paging=never --width=20Lunarvim config-- Read the docs: https://www.lunarvim.org/docs/configuration-- Example configs: https://github.com/LunarVim/starter.lvim-- Video Tutorials: https://www.youtube.com/watch?v=sFA9kX-Ud_c&amp;list=PLhoH5vyxr6QqGu0i7tt_XoVK9v-KvZ3m6-- Forum: https://www.reddit.com/r/lunarvim/-- Discord: https://discord.com/invite/Xb9B4Nylvim.plugins = {  {  'wfxr/minimap.vim',  build = \"cargo install --locked code-minimap\",  -- cmd = {\"Minimap\", \"MinimapClose\", \"MinimapToggle\", \"MinimapRefresh\", \"MinimapUpdateHighlight\"},  config = function ()    vim.cmd (\"let g:minimap_width = 10\")    vim.cmd (\"let g:minimap_auto_start = 1\")    vim.cmd (\"let g:minimap_auto_start_win_enter = 1\")  end,  },  {  'cappyzawa/trim.nvim',  config = function ()    require(\"trim\").setup({})  end  },  {  'tigion/nvim-asciidoc-preview',  cmd = { 'AsciiDocPreview' },  ft = { 'asciidoc' },  build = 'cd server &amp;&amp; npm install',  opts = {    -- Add user configuration here  },  }}vim.opt.shell = \"/bin/bash\"-- add `pyright` to `skipped_servers` listvim.list_extend(lvim.lsp.automatic_configuration.skipped_servers, { \"pyright\" })-- remove `jedi_language_server` from `skipped_servers` listlvim.lsp.automatic_configuration.skipped_servers = vim.tbl_filter(function(server)  return server ~= \"pylyzer\"end, lvim.lsp.automatic_configuration.skipped_servers)Tmux config# Setup CWD when splittingbind '\"' split-window -c \"#{pane_current_path}\"bind % split-window -h -c \"#{pane_current_path}\"## Colors and scrollingset -g default-terminal \"screen-256color\"#set -ga terminal-overrides \",*-256color:Tc\"set -g @plugin 'noscript/tmux-mighty-scroll'## Yankset -g mouse on#set -g @plugin 'tmux-plugins/tmux-yank'#set -g @yank_selection_mouse 'clipboard'#bind -T copy-mode-vi y send-keys -X copy-pipe-and-cancel 'xsel -i -b'bind-key -T copy-mode-vi MouseDragEnd1Pane send-keys -X copy-pipe-and-cancel \"xsel -i --clipboard\"#Ctrl+c to save tmux buffer to clipboardbind C-c run \"tmux save-buffer - | xsel -i -b\"setw -g mode-keys vibind P paste-bufferbind-key [ copy-modebind-key ] paste-buffer# Setup 'v' to begin selection as in Vimbind-key -T copy-mode-vi v send -X begin-selectionbind-key -T copy-mode-vi y send -X copy-pipe-and-cancel \"reattach-to-user-namespace pbcopy\"# Update default binding of `Enter` to also use copy-pipeunbind -T copy-mode-vi Enterbind-key -T copy-mode-vi Enter send -X copy-pipe-and-cancel \"reattach-to-user-namespace pbcopy\"set -g @plugin 'tmux-plugins/tmux-resurrect'#set -g @plugin 'tmux-plugins/tmux-sensible'set -g @plugin 'jaclu/tmux-menus'## Continuumset -g @plugin 'tmux-plugins/tmux-continuum'set -g @resurrect-capture-pane-contents 'on'set -g status-right 'Continuum status: #{continuum_status}'set -g @continuum-boot 'on'set -g @continuum-save-interval '5'set-option -g history-limit 50000bind-key r source-file ~/.tmux.conf \\; display-message \"tmux.conf reloaded.\"set -g @plugin 'laktak/extrakto'set -g @extrakto_fzf_tool '/home/filip/.fzf/bin/fzf'run '~/.tmux/plugins/tpm/tpm'set -g default-command /bin/fishset -g default-shell /bin/fish"
  },
  
  {
    "title": "Changing Prometheus TSDB directory",
    "url": "/posts/Changing-Prometheus-Data-dir/",
    "categories": "",
    "tags": "",
    "date": "2024-10-04 00:00:00 +0200",
    





    
    "snippet": "Changing Prometheus data directory  Stop prometheus and take backup    systemctl stop prometheussudo cp -vr /var/lib/prometheus /opt/intersec/prometheus_backup        Create new data directorychown...",
    "content": "Changing Prometheus data directory  Stop prometheus and take backup    systemctl stop prometheussudo cp -vr /var/lib/prometheus /opt/intersec/prometheus_backup        Create new data directorychown -R prometheus:prometheus /datasudo -u prometheus mkdir /data/prometheus  Change prometheus service to use new directoryvim /etc/systemd/system/prometheus.service[Unit]Description=PrometheusAfter=network-online.targetRequires=local-fs.targetAfter=local-fs.target[Service]Type=simpleEnvironment=\"GOMAXPROCS=8\"User=prometheusGroup=prometheusExecReload=/bin/kill -HUP $MAINPIDExecStart=/usr/local/bin/prometheus \\  --storage.tsdb.path=/data/prometheus \\  &lt;---------- CHANGE DIRECTORY HERE  --storage.tsdb.retention.time=30d \\  --storage.tsdb.retention.size=0 \\  --web.config.file=/etc/prometheus/web.yml \\  --web.console.libraries=/etc/prometheus/console_libraries \\  --web.console.templates=/etc/prometheus/consoles \\  --web.listen-address=0.0.0.0:9090 \\  --web.external-url= \\  --config.file=/etc/prometheus/prometheus.ymlCapabilityBoundingSet=CAP_SET_UIDLimitNOFILE=65000LockPersonality=trueNoNewPrivileges=trueMemoryDenyWriteExecute=truePrivateDevices=truePrivateTmp=trueProtectHome=trueRemoveIPC=trueRestrictSUIDSGID=true#SystemCallFilter=@signal @timerReadWritePaths=/data/prometheus   &lt;--------------- CHANGE DIRECTORY HEREPrivateUsers=trueProtectControlGroups=trueProtectKernelModules=trueProtectKernelTunables=trueProtectSystem=strictSyslogIdentifier=prometheusRestart=alwaysTimeoutStopSec=600s[Install]WantedBy=multi-user.target  Verify permissions and ownerls -al /data/ls -al /data/prometheus/root@dc2-monitoring-server-1:~# ls -al /data/prometheus/total 120drwxr-xr-x 25 prometheus prometheus  4096  4 oct.  09:54 .drwxr-xr-x  4 prometheus prometheus  4096  4 oct.  09:53 ..  Move the TSDB to new locationmv /var/lib/prometheus/* /data/prometheus/  Reload service file and start prometheus, verify if all is ok with journalctl and df    systemctl daemon-reloadsystemctl start prometheusjournalctl -xedf -h      "
  },
  
  {
    "title": "RIPGREP Search and replace",
    "url": "/posts/ripgrep-searchandreplace/",
    "categories": "",
    "tags": "",
    "date": "2024-06-14 00:00:00 +0200",
    





    
    "snippet": "RIPGREP Search and replacerg --passthru '/dev/mapper/vg_geosafe-sc-core' -r '/dev/mapper/vg_geosafe-sc--core' ansible/group_vars/node11 &gt; tmp.txt &amp;&amp; mv tmp.txt ansible/group_vars/node11c...",
    "content": "RIPGREP Search and replacerg --passthru '/dev/mapper/vg_geosafe-sc-core' -r '/dev/mapper/vg_geosafe-sc--core' ansible/group_vars/node11 &gt; tmp.txt &amp;&amp; mv tmp.txt ansible/group_vars/node11changes /dev/mapper/vg_geosafe-sc-core to /dev/mapper/vg_geosafe-sc–core and replaces it in the file"
  },
  
  {
    "title": "Resizing disk in Proxmox and guest VM",
    "url": "/posts/resizedisk/",
    "categories": "homelab, server, proxmox",
    "tags": "proxmox, ubuntu, resize, lvm, pv",
    "date": "2023-05-16 12:53:00 +0200",
    





    
    "snippet": "Resizing disk Proxmox+Ubuntu VMAfter resizing disk in Proxmox GUI:Inside parted:root@plex:/mnt/media/docker-volumes/photoprism# partedGNU Parted 3.4Using /dev/sdaWelcome to GNU Parted! Type 'help' ...",
    "content": "Resizing disk Proxmox+Ubuntu VMAfter resizing disk in Proxmox GUI:Inside parted:root@plex:/mnt/media/docker-volumes/photoprism# partedGNU Parted 3.4Using /dev/sdaWelcome to GNU Parted! Type 'help' to view a list of commands.(parted) printWarning: Not all of the space available to /dev/sda appears to be used, you can fix the GPT to use all of the space (an extra 41943040 blocks) or continue with the current setting?Fix/Ignore? FixModel: QEMU QEMU HARDDISK (scsi)Disk /dev/sda: 90.2GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number  Start   End     Size    File system  Name  Flags 1      1049kB  2097kB  1049kB                     bios_grub 2      2097kB  2150MB  2147MB  ext4 3      2150MB  68.7GB  66.6GB(parted) resizepart 3 100%(parted) printModel: QEMU QEMU HARDDISK (scsi)Disk /dev/sda: 90.2GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number  Start   End     Size    File system  Name  Flags 1      1049kB  2097kB  1049kB                     bios_grub 2      2097kB  2150MB  2147MB  ext4 3      2150MB  90.2GB  88.0GB(parted) ^CInformation: You may need to update /etc/fstab.After partedNeed to resize the Physical Volume and then the Logical Volume needs to extend to the max of the PV.root@plex:/mnt/media/docker-volumes/photoprism# pvresize /dev/sda3  Physical volume \"/dev/sda3\" changed  1 physical volume(s) resized or updated / 0 physical volume(s) not resizedroot@plex:/mnt/media/docker-volumes/photoprism# lvextend -r -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv  Size of logical volume ubuntu-vg/ubuntu-lv changed from &lt;62.00 GiB (15871 extents) to &lt;82.00 GiB (20991 extents).  Logical volume ubuntu-vg/ubuntu-lv successfully resized.resize2fs 1.46.5 (30-Dec-2021)Filesystem at /dev/mapper/ubuntu--vg-ubuntu--lv is mounted on /; on-line resizing requiredold_desc_blocks = 8, new_desc_blocks = 11The filesystem on /dev/mapper/ubuntu--vg-ubuntu--lv is now 21494784 (4k) blocks long."
  },
  
  {
    "title": "Building and installing my server",
    "url": "/posts/Migration-day/",
    "categories": "homelab, server, proxmox",
    "tags": "proxmox, nas, truenas",
    "date": "2023-05-08 18:00:00 +0200",
    





    
    "snippet": "  Created new dataset in TrueNas for docker-volumes only  Created volumes in Portainer that use NFS mounts  Had write issues with qBittorrent, ended up just chmod -R 773 for the download folder. No...",
    "content": "  Created new dataset in TrueNas for docker-volumes only  Created volumes in Portainer that use NFS mounts  Had write issues with qBittorrent, ended up just chmod -R 773 for the download folder. Not optimal, but I got lost with the different UIDs and GUIDs for the different folders  Had to increase RAM on my Ubuntu VM      Had to update config.xml on sonarr because it required authentication if coming from non local address    This fucking shit    [v3.0.10.1567] System.UnauthorizedAccessException: Access to the path '/data/TV SHOWS' is denied. ---&gt; System.IO.IOException: Permission denied --- End of inner exception stack trace ---at System.IO.Enumeration.FileSystemEnumerator`1[TResult].CreateDirectoryHandle (System.String path, System.Boolean ignoreNotFound) [0x00032] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0at System.IO.Enumeration.FileSystemEnumerator`1[TResult]..ctor (System.String directory, System.IO.EnumerationOptions options) [0x00048] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0at System.IO.Enumeration.FileSystemEnumerable`1+DelegateEnumerator[TResult]..ctor (System.IO.Enumeration.FileSystemEnumerable`1[TResult] enumerable) [0x00000] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0at System.IO.Enumeration.FileSystemEnumerable`1[TResult]..ctor (System.String directory, System.IO.Enumeration.FileSystemEnumerable`1+FindTransform[TResult] transform, System.IO.EnumerationOptions option) [0x00042] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0at System.IO.Enumeration.FileSystemEnumerableFactory.UserDirectories (System.String directory, System.String expression, System.IO.EnumerationOptions options) [0x00014] in &lt;de882a77e7c14f8ba5d298093dde822&gt;:0at System.IO.Directory.InternalEnumeratePaths (System.String path, System.String searchPattern, System.IO.SearchTarget searchTarget, System.IO.EnumerationOptions options) [0x00045] in &lt;de882a77e7c14f8ba5298093dde82b2&gt;:0at System.IO.Directory.GetDirectories (System.String path, System.String searchPattern, System.IO.EnumerationOptions enumerationOptions) [0x00000] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0at System.IO.Directory.GetDirectories (System.String path) [0x0000b] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0at NzbDrone.Common.Disk.DiskProviderBase.GetDirectories (System.String path) [0x00047] in C:\\BuildAgent\\work\\63739567f01dbcc2\\src\\NzbDrone.Common\\Disk\\DiskProviderBase.cs:157at NzbDrone.Core.RootFolders.RootFolderService.GetUnmappedFolders (System.String path, System.Collections.Generic.List`1[T] seriesPaths) [0x00055] in C:\\BuildAgent\\work\\63739567f01dbcc2\\src\\NzbDrone.CoreRootFolders\\RootFolderService.cs:142at NzbDrone.Core.RootFolders.RootFolderService+&lt;&gt;c__DisplayClass13_0.&lt;GetDetails&gt;b__0 () [0x00075] in C:\\BuildAgent\\work\\63739567f01dbcc2\\src\\NzbDrone.Core\\RootFolders\\RootFolderService.cs:191at System.Threading.Tasks.Task.InnerInvoke () [0x0000f] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0at System.Threading.Tasks.Task.Execute () [0x00000] in &lt;de882a77e7c14f8ba5d298093dde82b2&gt;:0        Fixed by giving read rights to other. Need to figure out how to make the container part of the group of the share.    Hardware transcoding isn’t working at all with my iGPU… Tried a lot of debugging and tinkering for which I won’t go into detail. I’ve decided to buy a GTX 1050Ti for 50 euros instead which will give me much better transcoding performance anyway.  Almost the entire stack was migrated but due to DB issues, Sonarr had to be reconfigured manually and also Nginx Proxy Manager gave me some issues when generating new certificates. Fixed NPM by actually portforwarding 80 and 443 ports to my server. Makes senseAnd with all that, I’ve finally migrated everything to the server. Although currently I’m still keeping Plex on my PC due to my PC having a dedicated GPU. But once I get my hands on a cheap GPU, I’ll be finished with the migration.Next on my todo:  Creating a mirrored pool from 2 6TB hard disks which will be divided into one partition for only backups and another bigger partition for a Nextcloud installation for which my entire family will have access to  Due to security concerns, Nextcloud won’t be exposed to the outside. It will only be accessible via VPN.  Will explore provisioning with Terraform  Will try to write a Ansible playbook for at least one of my servers.  Eventually will create a Windows VM for a remote desktop experience (accessible via VPN too)"
  },
  
  {
    "title": "Building and installing my server",
    "url": "/posts/ServerInstall/",
    "categories": "homelab, server, proxmox",
    "tags": "proxmox, nas, truenas",
    "date": "2023-05-06 18:00:00 +0200",
    





    
    "snippet": "  Couldn’t post after setting it up, turns out issue was RAM placement. Switched the places and it finally booted.  BIOS Config –&gt; Enable virtualization  Badly flashed the USB I guess, retried i...",
    "content": "  Couldn’t post after setting it up, turns out issue was RAM placement. Switched the places and it finally booted.  BIOS Config –&gt; Enable virtualization  Badly flashed the USB I guess, retried in Balena Etcher. Worked after disabling Secure boot :)Proxmox installationInstalled on 128gig SSD, IP Address : 192.168.1.160 because DHCP ends at .150Seems to work splendidly, next step: disable SSH password authentication and setup public key authentication insteadInstalled TrueNAS and passed through the two disks.root@pve:~# lsblk -o +MODEL,SERIALNAME                         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT MODEL                  SERIALsda                            8:0    0 111.8G  0 disk            WDC_WDS120G2G0A-00JH30 20451N458612├─sda1                         8:1    0  1007K  0 part├─sda2                         8:2    0     1G  0 part /boot/efi└─sda3                         8:3    0 110.8G  0 part  ├─pve-swap                 253:0    0     8G  0 lvm  [SWAP]  ├─pve-root                 253:1    0  37.7G  0 lvm  /  ├─pve-data_tmeta           253:2    0     1G  0 lvm  │ └─pve-data-tpool         253:4    0  49.3G  0 lvm  │   ├─pve-data             253:5    0  49.3G  1 lvm  │   └─pve-vm--100--disk--0 253:6    0    16G  0 lvm  └─pve-data_tdata           253:3    0  49.3G  0 lvm    └─pve-data-tpool         253:4    0  49.3G  0 lvm      ├─pve-data             253:5    0  49.3G  1 lvm      └─pve-vm--100--disk--0 253:6    0    16G  0 lvmsdb                            8:16   0   5.5T  0 disk            WDC_WD60EFPX-68C5ZN0   WD-WX62AC2DDET6sdc                            8:32   0   5.5T  0 disk            WDC_WD60EFPX-68C5ZN0   WD-WX72AC23P6STroot@pve:~# ls /dev/disk/by-id/ | grep WD-WX62AC2DDET6ata-WDC_WD60EFPX-68C5ZN0_WD-WX62AC2DDET6root@pve:~# ls /dev/disk/by-id/ | grep WD-WX72AC23P6STata-WDC_WD60EFPX-68C5ZN0_WD-WX72AC23P6STroot@pve:~# qm set 100 -scsi1 /dev/disk/by-id/ata-WDC_WD60EFPX-68C5ZN0_WD-WX62AC2DDET6update VM 100: -scsi1 /dev/disk/by-id/ata-WDC_WD60EFPX-68C5ZN0_WD-WX62AC2DDET6root@pve:~# qm set 100 -scsi2 /dev/disk/by-id/ata-WDC_WD60EFPX-68C5ZN0_WD-WX72AC23P6STupdate VM 100: -scsi2 /dev/disk/by-id/ata-WDC_WD60EFPX-68C5ZN0_WD-WX72AC23P6STLater on turned off all the extra fans because I want to be able to sleep at night :) In order to monitor this in the Proxmox summary tab, I had to edit some proxmox related files. Thanks to this reddit post for the great guide https://www.reddit.com/r/homelab/comments/rhq56e/displaying_cpu_temperature_in_proxmox_summery_in/vim /usr/share/perl5/PVE/API2/Nodes.pmvim /usr/share/pve-manager/js/pvemanagerlib.jsInside the first file, I added this line at line 407$res-&gt;{thermalstate} = `sensors`;Inside the second one, I had to change the padding in order to fit in the new information and then to print it out (my cpu has 6 cores so I had to add display info for the other 2)Ext.define('PVE.node.StatusView', {    extend: 'Proxmox.panel.StatusView',    alias: 'widget.pveNodeStatus',    height: 360,    bodyPadding: '15 20 15 20',        {            itemId: 'thermal',            colspan: 2,            printBar: false,            title: gettext('CPU Thermal State'),            textField: 'thermalstate',            renderer:function(value){                const c0 = value.match(/Core 0.*?\\+([\\d\\.]+)Â/)[1];                const c1 = value.match(/Core 1.*?\\+([\\d\\.]+)Â/)[1];                const c2 = value.match(/Core 2.*?\\+([\\d\\.]+)Â/)[1];                const c3 = value.match(/Core 3.*?\\+([\\d\\.]+)Â/)[1];                const c4 = value.match(/Core 4.*?\\+([\\d\\.]+)Â/)[1];                const c5 = value.match(/Core 5.*?\\+([\\d\\.]+)Â/)[1];                return `Core 0: ${c0} c | Core 1: ${c1} c | Core 2: ${c2} c | Core 3: ${c3} c | Core 4: ${c4} c | Core 5: ${c5} c`            }        }Storage pool creationSince I haven’t yet received my third drive which I will use in conjuction with another drive to do mirroring (this will be my backup pool and important documents), I will create a pool with only one disk which I’ll use to store media for Plex playback.Obviously I’m getting a bunch of warnings because there is 0 replication of any data with this kind of setup. For now, I do not mind as media isn’t something that’s completely unrecoverable by other means ;)I end up this config by adding a dataset which will server as a Samba share.Tried setting it up in LXC, but because of IOMMU, iGpu wasn’t showing up.      Set up ubuntu server with IOMMU and iGPU passthrough. Configured Network through    18  vim /etc/netplan/00-installer-config.yaml 19  netplan apply    network:ethernets:  ens18:    addresses:      - 192.168.1.162/24    routes:      - to: default        via: 192.168.1.1    dhcp4: false    nameservers:      addresses:      - 192.168.1.1      - 8.8.8.8      - 1.1.1.1      search:      - google.comversion: 2        Installed Docker, and Plex natively (for hardware encoding)  Set up ssh through public key authentication only (for both proxmox host and ubuntu vm)  Mounted aforementioned pool as a NFS share (and mapped root user to root)To do  Migrate volumes of all my docker containers running on WSL to my Share drive  Deploy my various stacks as compose files, with properly mounted config volumes as nfs  Configure nginx proxy manager and port forwarding  Decommission old Plex install in favor of this new one  Nextcloud  Windows VM  Terraform provisioning  VPN server"
  }
  
]

